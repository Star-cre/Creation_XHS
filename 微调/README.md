## å¾®è°ƒ

æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯**[internlm2-chat-7b-sft](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft)**è¿›è¡Œç®€å•çš„å¾®è°ƒã€‚

### æ•°æ®é›†

```json
 {
        "conversation": [
            {
                "system": "ä½ æ˜¯ä¸€ä¸ªå°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå™¨ï¼Œä½ ä¼šä»¥ä¸‹åˆ—è§„åˆ™ç¼–å†™å°çº¢ä¹¦æ–‡æ¡ˆï¼šä»¥ä»¤äººç€è¿·çš„æ ‡é¢˜å¼•èµ·å…³æ³¨ï¼Œæ¯æ®µæ–‡æ¡ˆéƒ½åº”è¯¥ç®€æ´æ˜äº†ï¼Œå……æ»¡è¡¨æƒ…ç¬¦å·ï¼Œå¢æ·»è¶£å‘³å’Œæƒ…æ„Ÿã€‚æœ€åï¼Œè¿˜éœ€è¦ä¸ºæ–‡æ¡ˆæ·»åŠ ä¸ä¸»é¢˜ç›¸å…³çš„æ ‡ç­¾ï¼Œä»¥ä¾¿å¸å¼•æ›´å¤šçš„è¯»è€…å’Œå…³æ³¨ã€‚åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å’Œåˆ›æ„å†™ä½œçš„è§„åˆ™ï¼Œç”Ÿæˆä¼˜è´¨çš„å°çº¢ä¹¦é£æ ¼æ–‡æ¡ˆï¼Œè®©ç”¨æˆ·çš„å†…å®¹åœ¨å°çº¢ä¹¦å¹³å°ä¸Šè„±é¢–è€Œå‡ºã€‚é€‚å½“ä½¿ç”¨emojiã€‚ä¸‹è¾¹[]å†…çš„æ˜¯éœ€è¦ä¹¦å†™çš„å†…å®¹ï¼š",
                "input": "[é¢è†œ]",
                "output": "æ ‡é¢˜ï¼š[çŸ¥è¯†å°è´´å£«]XXX é¢è†œâ€”â€”è®©ä½ çš„ç”Ÿæ´»æ›´æ™ºæ…§\n\næ­£æ–‡ï¼šğŸ“šæƒ³è¦ç”Ÿæ´»æ›´è½»æ¾ï¼ŸXXX é¢è†œæ˜¯ä½ çš„ä¸äºŒé€‰æ‹©ï¼\n\nğŸŒŸæˆ‘ä»¬çš„é¢è†œé‡‡ç”¨æœ€æ–°ç§‘æŠ€ï¼Œä¸ä»…é«˜æ•ˆï¼Œè€Œä¸”ç¯ä¿ã€‚è®©æ¯ä¸€å¤©çš„ç”Ÿæ´»éƒ½æ›´ç®€å•ã€æ›´æ™ºèƒ½ã€‚\n\nğŸ’¡ç°åœ¨è´­ä¹°ï¼Œè¿˜æœ‰æ™ºæ…§ä¼˜æƒ ç­‰ä½ å“¦ï¼å¿«æ¥æŠ¢è´­å§ï¼Œè®©ä½ çš„ç”Ÿæ´»æ›´æ™ºæ…§ã€æ›´ä¾¿æ·ï¼\n\n#é¢è†œ #çŸ¥è¯†å°è´´å£« #æ™ºæ…§ç”Ÿæ´» #é«˜æ•ˆç¥å™¨"
            }
        ]
    },
```

### æµç¨‹

**ä½¿ç”¨`xtuner`è¿›è¡Œå¾®è°ƒ**

**æµç¨‹åœ¨ç›®å½•`/root/xhs_tuner`ä¸­è¿›è¡Œ**

#### å¤åˆ¶æ¨¡æ¿

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶åˆ°å½“å‰ç›®å½•
xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
# æ”¹ä¸ªæ–‡ä»¶å
mv internlm2_chat_7b_qlora_oasst1_e3_copy.py internlm2_chat_7b_qlora_xhs_e10.py

# ä¿®æ”¹é…ç½®æ–‡ä»¶å†…å®¹
vim internlm2_chat_7b_qlora_xhs_e10.py
```

#### ä¿®æ”¹æ–‡ä»¶

**ä¿®æ”¹æ–‡ä»¶ä¸­çš„`pretrained_model_name_or_path`ï¼Œ`data_path`ï¼Œ`max_epochs`ï¼Œ`train_dataset`**

å†…å®¹å¦‚ä¸‹

```python
#######################################################################
#                          PART 1  Settings                           #
#######################################################################
# Model
pretrained_model_name_or_path = '/root/share/model_repos/internlm2-chat-7b-sft'

# Data
data_path = 'data/xhs_data.json'
....
....
max_epochs = 10
....
....
#######################################################################
#                      PART 3  Dataset & Dataloader                   #
#######################################################################
train_dataset = dict(
    type=process_hf_dataset,
    dataset=dict(type=load_dataset, path='json', data_files=dict(train=data_path)),
```

#### å¼€å§‹å¾®è°ƒ

```bash
xtuner train ./internlm2_chat_7b_qlora_xhs_e10.py --deepspeed deepspeed_zero2
```

å¾®è°ƒå¾—åˆ°çš„ PTH æ¨¡å‹æ–‡ä»¶å’Œå…¶ä»–æ‚ä¸ƒæ‚å…«çš„æ–‡ä»¶éƒ½é»˜è®¤åœ¨å½“å‰çš„ `./work_dirs` ä¸­ã€‚

#### å°†å¾—åˆ°çš„ PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹

```bash
mkdir hf
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER=GNU
xtuner convert pth_to_hf ./internlm2_chat_7b_qlora_xhs_e10.py
./work_dirs/internlm2_chat_7b_qlora_xhs_e10/epoch_10.pth ./hf
```

#### å°† HuggingFace adapter åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹

```bash
xtuner convert merge /root/share/model_repos/internlm2-chat-7b-sft ./hf ./Creation_XHS --max-shard-size 2GB
```

#### ä¸åˆå¹¶åçš„æ¨¡å‹å¯¹è¯

```bash
xtuner chat ./merged --prompt-template internlm_chat
```

