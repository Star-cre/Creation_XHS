import streamlit as st
from PIL import Image, ImageDraw, ImageFont
from zhipuai import ZhipuAI
import requests
from io import BytesIO
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig
import torch
import streamlit as st
from modelscope import snapshot_download

# ä¾§è¾¹æ ä¸­åˆ›å»ºæ ‡é¢˜å’Œé“¾æ¥
with st.sidebar:
    st.markdown("## InternLM LLM")
    "[InternLM](https://github.com/InternLM/InternLM.git)"
    "[å¼€æºå¤§æ¨¡å‹é£Ÿç”¨æŒ‡å— self-llm](https://github.com/datawhalechina/self-llm.git)"
    "[![å°çº¢ä¹¦ç¾å¦†æ–‡æ¡ˆç”Ÿæˆå¯¼å¸ˆ](https://github.com/codespaces/badge.svg)](https://github.com/Star-cre/Creation_XHS)"

# è®¾ç½®æ ‡é¢˜å’Œå‰¯æ ‡é¢˜
st.title("ğŸ’¬ : æ–‡å­—è½¬å›¾ç‰‡")
st.caption("ğŸš€ A streamlit APP powered by æ™ºè°±AI")


def blog_outline(topic):
    api_key = "d93d034e042e186b6cd605c6bb6fd31f.ApkLkpE8XiFAFkF2"
    client = ZhipuAI(api_key=api_key)  # è¯·å¡«å†™æ‚¨è‡ªå·±çš„APIKey
    response = client.images.generations(
        model="cogview-3",  # å¡«å†™éœ€è¦è°ƒç”¨çš„æ¨¡å‹åç§°
        #     prompt=f'è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡ˆç”Ÿæˆäº§å“å›¾ï¼š{prompt},å‚è€ƒæç¤ºè¯ï¼š{short_prompt}',
        prompt=topic,
    )
    # å¾—åˆ°å›¾ç‰‡çš„URL
    url_of_image = response.data[0].url
    generated_image = get_image_from_url(url_of_image)
    st.image(generated_image, caption="Generated Image", use_column_width=True)

def get_image_from_url(image_url):
    # å‘é€ HTTP è¯·æ±‚å¹¶ä¸‹è½½å›¾ç‰‡
    response = requests.get(image_url)
    # æ£€æŸ¥å“åº”çŠ¶æ€ç 
    if response.status_code == 200:
        # ä»å“åº”ä¸­è·å–å›¾åƒæ•°æ®
        image_data = response.content
        # å°†å›¾åƒæ•°æ®è½¬æ¢ä¸º PIL å›¾åƒå¯¹è±¡
        image = Image.open(BytesIO(image_data))
        # æ˜¾ç¤ºå›¾åƒ
        # image.show()
        return image
    else:
        print("Failed to download image. Status code:", response.status_code)


with st.form("myform"):
    topic_text = st.text_input("Enter prompt:", "")
    submitted = st.form_submit_button("Submit")
    if submitted:
        blog_outline(topic_text)

